{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-packing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T14:22:16.610471Z",
     "iopub.status.busy": "2021-02-23T14:22:16.610129Z",
     "iopub.status.idle": "2021-02-23T14:22:16.627784Z",
     "shell.execute_reply": "2021-02-23T14:22:16.626866Z",
     "shell.execute_reply.started": "2021-02-23T14:22:16.610384Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-wilson",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# spaCy - SpaCy Build a sentiment analysis model using Twitter\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/spaCy/SpaCy_Build_a_sentiment_analysis_model_using_Twitter.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/open_in_naas.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-programmer",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #twitter #spaCy #data #nlp #sentiment #classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e948d7f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Tannia Dubon](https://www.linkedin.com/in/tanniadubon/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd62ac",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Tweets are retrieved using the Twitter Developer Platform and spaCy models are used for natural language processing.\n",
    "\n",
    "Binary classification is used to score the sentiment of the tweets; 1 designated as positive, 0 as negative and a .5 threshold. <br>\n",
    "\n",
    "Use this Notebook to update the query and conduct your own research! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-truth",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-mediterranean",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Install required packages as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-surfing",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --user requests pandas pyyaml datetime numpy datetime matplotlib wordcloud seaborn spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf094d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "import warnings\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-trustee",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Bearer Token to Use Twitter API\n",
    "\n",
    "#### How to get a bearer token ?\n",
    "\n",
    "bearer_token – the token used for authentication https://developer.twitter.com/en/docs/authentication/oauth-2-0/bearer-tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-melbourne",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "BEARER_TOKEN = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838a83f-52c6-44d2-aac4-d1217b41f095",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Setup Twitter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ea700-a1d4-449d-a6d1-1d078c8d4d1c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Twitter query to fetch tweets. Learn how to build one here: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "TWITTER_QUERY = '(Putin OR Lukashenka OR Russia OR \"Vladimir Putin\") -is:retweet lang:en'\n",
    "\n",
    "# Number of tweets to fetch (max 100).\n",
    "TWITTER_MAX_RESULTS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-showcase",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5dbcac",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Retrieve data from Twitter\n",
    "Enter keywords for query in the create_url() function. \n",
    "See https://tinyurl.com/2j5phrhu for instructions on customizing your query syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7563be",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_url(query, max_results=100):\n",
    "    tweet_fields = \"tweet.fields=created_at,public_metrics,context_annotations,text,possibly_sensitive,geo\"\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?max_results={}&query={}&{}\".format(max_results, query, tweet_fields)\n",
    "    return url\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9806e9e-dae1-4958-9904-736ed4055db1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Download tweets and store them in a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093019b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "url= create_url(TWITTER_QUERY, TWITTER_MAX_RESULTS)\n",
    "bearer_token = BEARER_TOKEN\n",
    "headers = create_headers(bearer_token)\n",
    "json_response = connect_to_endpoint(url, headers)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44cf5f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Define functions to retrieve each tweet field of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21cf65",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize Lists\n",
    "id_data = []\n",
    "date_data = [] \n",
    "rtwt_data = []\n",
    "reply_data = []\n",
    "text_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88e4cb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_id():\n",
    "    for data in json_response[\"data\"]:\n",
    "        id_record = data[\"id\"]\n",
    "        id_data.append(id_record)\n",
    "\n",
    "def get_created_at():\n",
    "    for data in json_response[\"data\"]:\n",
    "        date_record = data[\"created_at\"]\n",
    "        date_data.append(date_record)\n",
    "\n",
    "def retweet_count():\n",
    "    for retweets in json_response[\"data\"]:\n",
    "        rtwt_count=retweets[\"public_metrics\"][\"retweet_count\"] \n",
    "        rtwt_data.append(rtwt_count)\n",
    "\n",
    "def reply_count():\n",
    "    for reply in json_response[\"data\"]:\n",
    "        reply_count = reply[\"public_metrics\"][\"reply_count\"]\n",
    "        reply_data.append(reply_count)\n",
    "\n",
    "        \n",
    "def get_text():\n",
    "    for data in json_response[\"data\"]:\n",
    "        text_record = data[\"text\"]\n",
    "        text_data.append(text_record)\n",
    "        \n",
    "get_id() \n",
    "get_created_at() \n",
    "retweet_count()\n",
    "reply_count() \n",
    "get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a080ba2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_domain():\n",
    "    d_id = []\n",
    "    d_name = []\n",
    "    d_desc = []\n",
    "    d_twt_id = []\n",
    "    \n",
    "    for j in json_response[\"data\"]:\n",
    "        for i in j:\n",
    "            if i == \"context_annotations\":\n",
    "                for d in j[\"context_annotations\"]:\n",
    "                    d_id.append(d[\"domain\"][\"id\"])\n",
    "                    d_name.append(d[\"domain\"][\"name\"])\n",
    "                    d_desc.append(d[\"domain\"][\"description\"])\n",
    "                    d_twt_id.append(j[\"id\"])\n",
    "                    \n",
    "    domain = {\"id\": d_id, \"name\": d_name, \"desc\": d_desc,\"tweet id\": d_twt_id}\n",
    "    return domain\n",
    "\n",
    "\n",
    "def get_entity():    \n",
    "    e_id = []\n",
    "    e_name = []\n",
    "    e_desc = []\n",
    "    e_twt_id = []\n",
    "\n",
    "    for j in json_response[\"data\"]:\n",
    "        for i in j:\n",
    "            if i == \"context_annotations\":\n",
    "                for d in j[\"context_annotations\"]:\n",
    "                    e_id.append(d[\"entity\"][\"id\"])\n",
    "                    e_name.append(d[\"entity\"][\"name\"])\n",
    "                    e_twt_id.append(j[\"id\"])\n",
    "                \n",
    "    entity = {\"id\": e_id, \"name\": e_name, \"desc\": e_desc,\"tweet id\": e_twt_id}\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0554a-1704-4f8c-bbd8-9c2a1c620a71",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inspect output\n",
    "print(get_entity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a606e5c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(get_domain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a8d7f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(id_data), len(date_data), len(rtwt_data), len(reply_data), len(text_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016a345",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save data to pandas dataframe and clean and format text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e14bd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saved tweet fields doe not include entity or domain data\n",
    "save_data = {\"id\": id_data, \"date\": date_data, \"retweet count\": rtwt_data, \"reply count\": reply_data, \"text\": text_data}\n",
    "df = pd.DataFrame(save_data)\n",
    "df.to_csv(\"pol_tweet_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360510d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup_text(file, rem_item):\n",
    "    r = re.findall(rem_item, file)\n",
    "    for i in r:\n",
    "        file = re.sub(i, \"\", file)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed206aa",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove handles\n",
    "df[\"clean text\"] = np.vectorize(cleanup_text)(df[\"text\"], \"@[\\w]*\")\n",
    "df[\"clean text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd595db",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df[\"clean text\"])\n",
    "print(df[\"clean text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ea421",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Tokenize text in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25aa678",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert to tokens\n",
    "nlp = None\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\") #here you can load a model that you'd previously trained\n",
    "except:\n",
    "    ! python -m spacy download en_core_web_lg\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    \n",
    "text = str(df[\"clean text\"])\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74af8c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_list = [] \n",
    "for token in doc:\n",
    "    tokens_list.append(token)\n",
    "\n",
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c132a5b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Review entities recognized\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aac127",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add a category for entities of interest, if needed. \n",
    "from spacy.matcher import PhraseMatcher \n",
    "matcher = PhraseMatcher(nlp.vocab) \n",
    "\n",
    "#define politicians as entities \n",
    "terms = [\"Putin\", \"Zelensky\"] \n",
    "patterns = [nlp.make_doc(term) for term in terms] \n",
    "matcher.add(\"politiciansList\", None, *patterns) \n",
    "\n",
    "matches = matcher(doc) \n",
    "\n",
    "#this prints out the spans where the instances are found and the entity identified\n",
    "for mid, start, end in matches: \n",
    "    print(start, end, doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-astrology",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-louisville",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"threshold\": 0.5,\n",
    "    \"model\": DEFAULT_SINGLE_TEXTCAT_MODEL }\n",
    "\n",
    "textcat = nlp.add_pipe(\"textcat\", config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48120d6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create training data for your example consisting of examples of positive and negative sentiment\n",
    "train_data = [(\"Helping refugees. This is what kindness looks like.\", {\"cats\": {\"POS\": True}}),\n",
    "              (\"In this time of uncertainty, we have a clear way forward: Help Ukraine defend itself. Support the Ukrainian people. Hold Russia accountable.\", {\"cats\": {\"POS\": True}}),\n",
    "              (\"Priests demand head of Ukrainian Orthodox Church Moscow Patriarchate be brought to church tribunal for position on war.\", {\"cats\": {\"POS\": True}}),\n",
    "              (\"Mayor of the most northern village in Ukraine Hremiach Hanna Havrylina was released after yesterday’s prisoners’ swap.\", {\"cats\": {\"POS\": True}}),\n",
    "              (\"Look at this female volunteer from Belarus fighting alongside Ukrainians.\", {\"cats\": {\"POS\": True}}),\n",
    "              (\"Russian soldiers: They're animals... Humans don't behave like this. My parents told me about WW2 & the fascists didn't even do such things.\", {\"cats\": {\"NEG\": True}}),\n",
    "              (\"All Russians are evil\", {\"cats\": {\"NEG\": True}}),\n",
    "              (\"The West is pushing Ukraine toward a conflict.\", {\"cats\": {\"NEG\": True}}),\n",
    "              (\"Cowards\", {\"cats\": {\"NEG\": True}}),\n",
    "              (\"Russia’s deployment of combat forces is a mere repositioning of troops on its own territory.\", {\"cats\": {\"NEG\": True}}),\n",
    "              (\"Ukraine and Ukrainian government officials are the aggressor in the Russia-Ukraine relationship.\", {\"cats\": {\"NEG\": True}})] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0800a4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "textcat.add_label(\"POS\")\n",
    "textcat.add_label(\"NEG\")\n",
    "    \n",
    "train_examples = [Example.from_dict(nlp.make_doc(text), label) for text,label in train_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4b9e4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "textcat.initialize(lambda: train_examples, nlp=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4c58c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define training example\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "#Disable other pipe components & define training loop to incorporate statistical information\n",
    "\n",
    "with nlp.select_pipes(enable=\"textcat\"):\n",
    "    optimizer = nlp.resume_training() #Creates optimizer object\n",
    "    for i in range(epochs):\n",
    "        random.shuffle(train_data)\n",
    "        for text, label in train_data:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, label) \n",
    "            print(nlp.update([example], sgd=optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd3f35",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#enter an example tweet to test results\n",
    "doc2 = nlp(\"As Russia continues to commit horrific atrocities against the Ukrainian people, we must take additional steps to cut off\")\n",
    "\n",
    "print(doc2.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a43e2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#enter another example\n",
    "doc3 = nlp(\"One of the captured Russian soldiers who was sent by Putin to “denazify” Ukraine\")\n",
    "print(doc3.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64144cf3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#process each row in clean text column\n",
    "df[\"nlp_proc\"] = [nlp(i) for i in df[\"clean text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c352a9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save positive/negative predictions to cats column\n",
    "df[\"cats\"] = [i.cats for i in df[\"nlp_proc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38daf1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assign value of 1 to positive classification, 0 to negative\n",
    "sc_val = []\n",
    "\n",
    "for i in df[\"cats\"]:\n",
    "    if i[\"POS\"] >= .5:\n",
    "        sc_val.append(1)\n",
    "    else:\n",
    "        sc_val.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd62bc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#append classification score to dataframe\n",
    "df[\"score\"] = sc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1a3bf",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38e976",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print out tweet id, text and score = to review results\n",
    "for index, i in enumerate(df[\"score\"]):\n",
    "    if i == 1:\n",
    "        print(df[\"id\"][index], df[\"clean text\"][index], df[\"score\"][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-pacific",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T23:32:10.789097Z",
     "iopub.status.busy": "2021-07-02T23:32:10.788829Z",
     "iopub.status.idle": "2021-07-02T23:32:10.796900Z",
     "shell.execute_reply": "2021-07-02T23:32:10.796358Z",
     "shell.execute_reply.started": "2021-07-02T23:32:10.789033Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-address",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Display wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-poetry",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wordcloud\n",
    "wordcloud = WordCloud(stopwords = STOPWORDS, collocations=True).generate(str(tokens_list))\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdefc1a-81eb-4473-abc2-3364256e291f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Plot positive vs negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1dbfd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = df.score.value_counts().plot(kind=\"bar\", colormap=\"Paired\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206ebc2-dbb2-41a4-8e29-df7d8aa02648",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073809c0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_dir=Path(\"spaCy_models\")\n",
    "\n",
    "def save_model(output_dir):\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "        \n",
    "save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39013dcc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "### To load trained, custom model on new data use:\n",
    "#nlp = spacy.load(\"spaCy_models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}