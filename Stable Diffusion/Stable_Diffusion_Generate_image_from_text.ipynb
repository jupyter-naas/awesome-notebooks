{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2faefb65-f69c-494d-8b8c-b74b72f687e5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Stable Diffusion.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Stable%20Diffusion.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89373c-f251-4796-b5ea-a246574c53ea",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Stable Diffusion - Generate image from text\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=Stable+Diffusion+-+Generate+image+from+text:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133d291-e951-4ea7-9ecf-51f6416a4e87",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #stable-diffusion #image-generation #text-to-image #ai #machine-learning #deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e02164-25a4-4c5c-8789-4bea92046bf5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Oussama El Bahaoui](https://www.linkedin.com/in/oelbahaoui/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43df35-89d0-4f53-bab8-b9cc27cdda19",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-06-19 (Created: 2023-05-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc3252-4ffd-4610-b64d-aebce7aa2f1b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook generate image from text using Stable Diffusion.\n",
    "\n",
    "It requires a more powerful machine than the free tier we provide. You have two options to proceed:\n",
    "\n",
    "1. **Using Google Colab:** If you have a Google account, you can open this notebook in Google Colab(link is above), which provides free access to more powerful computational resources to run this notebook. To do this, click the “Open in Colab” button located at the end of this paragraph. Please note that you may need to sign in with your Google account or create one if you don’t have it. <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1PYhRAo8bcgSJdIFrtAFUF2ENbe5BJhn7?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "2. **Contacting Us for Machine Upgrade:** If you prefer to run this notebook on your own machine, you can contact us to upgrade your machine. Our team will assist you in setting up the necessary environment. Please reach out to [Jeremy Ravenel](mailto:jeremy@naas.ai) for further assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b79c1-a7a4-42a6-8e39-9ce02bd3191d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "- [Stability.ai - Stable Diffusion](https://stability.ai/stable-diffusion)\n",
    "- [Stability.ai - Text to Image](https://stability.ai/text-to-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe8b29-61d1-4d67-af75-afeb20191533",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef74fc9-5b1d-46e2-a807-0d9ace1d3cb4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Install and update libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e910b4c-ce74-4341-86ca-b2b99625ef0f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --user --upgrade transformers diffusers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e5c84-3ead-4dd5-b8bf-2901e9aa6d89",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148eb6f",
   "metadata": {
    "papermill": {},
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b873d07-9acd-4a46-88c9-78b64a5e8119",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Variables\n",
    "- `REPO_ID`: This variable stores the identifier for the model repository that will be used. In this example, it is set to \"stabilityai/stable-diffusion-2\" to specify the specific model from the \"stabilityai\" repository.\n",
    "- `NUM_INFERENCE_STEPS`: This variable defines the number of steps or iterations the model will take during the inference process. It determines how many times the model will update its predictions.\n",
    "- `prompt`: This variable represents the description or prompt that will be provided to the model. It serves as the basis for generating the image output. In this case, the prompt is set to \"A person walking through a field of tall grass\".\n",
    "- `IMAGE_PATH`: This variable specifies the path or file name for the output image. The generated image will be saved at the location specified by this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cadc2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Inputs\n",
    "# Model to use: this is the identifier for the model repository that we're going to use. \n",
    "# In this case, we're using the \"stable-diffusion-2\" model from the \"stabilityai\" repository.\n",
    "REPO_ID = \"stabilityai/stable-diffusion-2\"\n",
    "\n",
    "# This is the number of steps the model will take during inference. \n",
    "# In other words, this is the number of times the model will update its predictions.\n",
    "NUM_INFERENCE_STEPS = 25\n",
    "\n",
    "# Define the prompt: this is the description that the model will use as a basis to generate the image. \n",
    "prompt = \"A person walking through a field of tall grass\"\n",
    "\n",
    "## Output\n",
    "IMAGE_PATH = \"output.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e6e7b-035a-48c5-94a5-46d6f31da099",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3215937-5c37-4b72-a3b9-dd155dda64a1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Generate image from text\n",
    "\n",
    "Using Stable Diffusion, we can generate an image from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeaacb9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the DiffusionPipeline\n",
    "# This pipeline is created using a pretrained model from the specified repository. \n",
    "# We specify that the model should use 16-bit floating point precision for its computations \n",
    "# (which can help to save memory and improve computational speed, with a slight tradeoff in precision).\n",
    "# We also specify the revision of the model to be \"fp16\".\n",
    "pipe = DiffusionPipeline.from_pretrained(REPO_ID, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "\n",
    "# Modify the scheduler of the pipeline\n",
    "# The scheduler determines the timing of the steps in the diffusion process.\n",
    "# Here, we're creating a new scheduler from the configuration of the current one, which effectively keeps the current scheduler's settings.\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Move the pipeline to GPU\n",
    "# This moves all the computations of the pipeline to the GPU, which is typically much faster than the CPU for these types of tasks.\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e97847-1d33-46f1-a73f-3ae2c1c12674",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf75423-adfc-4fee-8f42-a889bcecdccd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Generate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56688e5b-e92b-4351-bfd5-6576b0fdce70",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate an image from a prompt\n",
    "# This line uses the diffusion pipeline to generate an image from the provided prompt.\n",
    "# The number of inference steps specified is used in the generation process.\n",
    "# The output of the pipeline is a batch of images, and we're taking the first one from this batch.\n",
    "image = pipe(prompt, num_inference_steps=NUM_INFERENCE_STEPS).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf4d7f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save and display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d4974",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the image\n",
    "image.save(IMAGE_PATH)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "img = Image.open(IMAGE_PATH)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "832c6caba950d6fab4bf84f56f9ec0661ca43ffc478e0f39bf5ba999022a6e17",
   "notebook_path": "Stable Diffusion/Stable_Diffusion_Generate_image_from_text.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}