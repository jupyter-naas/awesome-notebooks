{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61a36dd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177a648",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Remotive - Send jobs to gsheet\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/Remotive/Remotive_Send_jobs_to_gsheet.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/open_in_naas.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e00547",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #remotive #jobs #gsheet #naas_drivers #automation #opendata #googlesheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdffa9c4-e507-4ae5-b2e7-bf98fc14d05c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/ACoAABCNSioBW3YZHc2lBHVG0E_TXYWitQkmwog/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a212b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139398d4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b470ca",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "from naas_drivers import gsheet\n",
    "import naas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10854ebc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Gsheet log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b90fc7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "spreadsheet_id = \"1EBefhkbmqaXMZLRCiafaxxxxxxxxxxxxxxxx\"\n",
    "sheet_name = \"SLACK_CHANNEL_POSTS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4b35c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Remotive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4035aaa",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Get categories from Remotive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b27f35",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_remotejob_categories():\n",
    "    req_url = f\"https://remotive.io/api/remote-jobs/categories\"\n",
    "    res = requests.get(req_url)\n",
    "    try:\n",
    "        res.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        return e\n",
    "    res_json = res.json()\n",
    "    \n",
    "    # Get categories\n",
    "    jobs = res_json.get('jobs')\n",
    "    return pd.DataFrame(jobs)\n",
    "\n",
    "df_categories = get_remotejob_categories()\n",
    "df_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e3df8",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Enter your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ed6f9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['data'] # Pick the list of categories in columns \"slug\"\n",
    "date_from = - 10 # Choose date difference in days from now => must be negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f650d6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Set the Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa9789",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "naas.scheduler.add(recurrence=\"0 9 * * *\")\n",
    "# # naas.scheduler.delete() # Uncomment this line to delete your scheduler if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c0acc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c20e95",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get the sheet log of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e352e6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jobs_log = gsheet.connect(spreadsheet_id).get(sheet_name=sheet_name)\n",
    "df_jobs_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e581fb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get all jobs posted after timestamp_date\n",
    "\n",
    "All jobs posted after the date from will be fetched.<br>\n",
    "In summary, we can set the value, in seconds, of 'search_data_from' to fetch all jobs posted since this duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfcdad",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "REMOTIVE_DATETIME = \"%Y-%m-%dT%H:%M:%S\"\n",
    "NAAS_DATETIME = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "def get_remotive_jobs_since(jobs, date):\n",
    "    ret = []\n",
    "    for job in jobs:\n",
    "        publication_date = datetime.strptime(job['publication_date'], REMOTIVE_DATETIME).timestamp()\n",
    "        if publication_date > date:\n",
    "            ret.append({\n",
    "                'URL': job['url'],\n",
    "                'TITLE': job['title'],\n",
    "                'COMPANY': job['company_name'],\n",
    "                'PUBLICATION_DATE': datetime.fromtimestamp(publication_date).strftime(NAAS_DATETIME)\n",
    "            })\n",
    "    return ret\n",
    "\n",
    "def get_category_jobs_since(category, date, limit):\n",
    "    url = f\"https://remotive.io/api/remote-jobs?category={category}&limit={limit}\"\n",
    "    res = requests.get(url)\n",
    "    if res.json()['jobs']:\n",
    "        publication_date = datetime.strptime(res.json()['jobs'][-1]['publication_date'], REMOTIVE_DATETIME).timestamp()\n",
    "        if len(res.json()['jobs']) < limit or date > publication_date:\n",
    "            print(f\"Jobs from catgory {category} fetched \u2705\")\n",
    "            return get_remotive_jobs_since(res.json()['jobs'], date)\n",
    "        else:\n",
    "            return get_category_jobs_since(category, date, limit + 5)\n",
    "    return []\n",
    "\n",
    "def get_jobs_since(categories: list,\n",
    "                   date_from: int):\n",
    "    if date_from >= 0:\n",
    "        return(\"'date_from' must be negative. Please update your parameter.\")\n",
    "    # Transform datefrom int to\n",
    "    search_jobs_from = date_from * 24 * 60 * 60   # days in seconds\n",
    "    timestamp_date = time.time() + search_jobs_from\n",
    "\n",
    "    jobs = []\n",
    "    for category in categories:\n",
    "        jobs += get_category_jobs_since(category, timestamp_date, 5)\n",
    "    print(f'- All job since {datetime.fromtimestamp(timestamp_date)} have been fetched -')\n",
    "    return pd.DataFrame(jobs)\n",
    "\n",
    "df_jobs = get_jobs_since(categories, date_from=date_from)\n",
    "df_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8628f34",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Remove duplicate jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc0cdb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(df1, df2):\n",
    "    # Get jobs log\n",
    "    jobs_log = df1.URL.unique()\n",
    "    \n",
    "    # Exclude jobs already log from jobs\n",
    "    df2 = df2[~df2.URL.isin(jobs_log)]\n",
    "    return df2.sort_values(by=\"PUBLICATION_DATE\")\n",
    "\n",
    "df_new_jobs = remove_duplicates(df_jobs_log, df_jobs)\n",
    "df_new_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359f809",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff31cb7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Add new jobs on the sheet log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671a141",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "gsheet.connect(spreadsheet_id).send(sheet_name=sheet_name,\n",
    "                                    data=df_new_jobs,\n",
    "                                    append=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.4"
  },
  "naas": {
   "notebook_path": "Remotive/Remotive_Send_jobs_to_gsheet.ipynb",
   "notebook_id": "70df4ca5-17bc-4486-ab8a-73268bf53f4e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}