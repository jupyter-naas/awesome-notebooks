{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "different-viking",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Hugging Face - Ask boolean question to T5\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/Hugging%20Face/Hugging_Face_Ask_boolean_question_to_T5.ipynb\" target=\"_parent\">\n",
    "<img src=\"https://img.shields.io/badge/-Open%20in%20Naas-success?labelColor=000000&logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iMTAyNHB4IiBoZWlnaHQ9IjEwMjRweCIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgdmVyc2lvbj0iMS4xIj4KIDwhLS0gR2VuZXJhdGVkIGJ5IFBpeGVsbWF0b3IgUHJvIDIuMC41IC0tPgogPGRlZnM+CiAgPHRleHQgaWQ9InN0cmluZyIgdHJhbnNmb3JtPSJtYXRyaXgoMS4wIDAuMCAwLjAgMS4wIDIyOC4wIDU0LjUpIiBmb250LWZhbWlseT0iQ29tZm9ydGFhLVJlZ3VsYXIsIENvbWZvcnRhYSIgZm9udC1zaXplPSI4MDAiIHRleHQtZGVjb3JhdGlvbj0ibm9uZSIgZmlsbD0iI2ZmZmZmZiIgeD0iMS4xOTk5OTk5OTk5OTk5ODg2IiB5PSI3MDUuMCI+bjwvdGV4dD4KIDwvZGVmcz4KIDx1c2UgaWQ9Im4iIHhsaW5rOmhyZWY9IiNzdHJpbmciLz4KPC9zdmc+Cg==\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-bachelor",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## T5-base finetuned on BoolQ (superglue task)\n",
    "This notebook is for demonstrating the training and use of the text-to-text-transfer-transformer (better known as T5) on boolean questions (BoolQ). The example use case is a validator indicating if an idea is environmentally friendly. Nearly any question can be passed into the `query` function (see below) as long as a context to a question is given.\n",
    "\n",
    "Author: Maximilian Frank ([script4all.com](//script4all.com)) - Copyleft license\n",
    "\n",
    "Notes:\n",
    "- The model from [huggingface.co/mrm8488/t5-base-finetuned-boolq](//huggingface.co/mrm8488/t5-base-finetuned-boolq) is used in this example as it is an already trained t5-base model on boolean questions (BoolQ task of superglue).\n",
    "- Documentation references on [huggingface.co/transformers/model_doc/t5.html#training](//huggingface.co/transformers/model_doc/t5.html#training), template script on [programming-review.com/machine-learning/t5](//programming-review.com/machine-learning/t5)\n",
    "- The greater the model, the higher the accuracy on BoolQ (see [arxiv.org/pdf/1910.10683.pdf](//arxiv.org/pdf/1910.10683.pdf)):\n",
    "    t5-small|t5-base|t5-large|t5-3B|t5-11B\n",
    "    -|-|-|-|-\n",
    "    76.4%|81.4%|85.4%|89.9%|91.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-replication",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Loading the model\n",
    "If here comes an error, install the packages via `python3 -m pip install â€¦ --user`.\n",
    "\n",
    "You can also load a T5 plain model (not finetuned). Just replace the following code\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('mrm8488/t5-base-finetuned-boolq')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('mrm8488/t5-base-finetuned-boolq')â€¦\n",
    "```\n",
    "with\n",
    "```python\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "```\n",
    "where `t5-small` is one of the names in the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-smell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install transformers\n",
    "#pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extensive-movement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T05:17:25.351132Z",
     "iopub.status.busy": "2021-05-08T05:17:25.350861Z",
     "iopub.status.idle": "2021-05-08T05:17:27.173947Z",
     "shell.execute_reply": "2021-05-08T05:17:27.173309Z",
     "shell.execute_reply.started": "2021-05-08T05:17:25.351067Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from operator import itemgetter\n",
    "from distutils.util import strtobool\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-leadership",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T05:17:29.455469Z",
     "iopub.status.busy": "2021-05-08T05:17:29.455239Z",
     "iopub.status.idle": "2021-05-08T05:17:47.738897Z",
     "shell.execute_reply": "2021-05-08T05:17:47.738226Z",
     "shell.execute_reply.started": "2021-05-08T05:17:29.455444Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "tokenizer = AutoTokenizer.from_pretrained('mrm8488/t5-base-finetuned-boolq')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('mrm8488/t5-base-finetuned-boolq').to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "try:model.parallelize()\n",
    "except:pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-valentine",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Training\n",
    "> **Optional:** You can leave the following out, if you don't have custom datasets. By default the number of training epochs equals 0, so nothing is trained.\n",
    "\n",
    "> **Warning:** This option consumes a lot of runtime and thus *naas.ai* credits. Make sure to have enough credits on your account.\n",
    "\n",
    "For each dataset a stream-opener has to be provided which is readable line by line (e.g. file, database). In the array with key `keys` are all dictionary keys which exist in the jsonl-line. So in this example the first training dataset has the keys `question` for the questions (string),`passage` for the contexts (string) and `answer` for the answers (boolean). Adjust these keys to your dataset.\n",
    "\n",
    "At last you have to adjust the number of epochs to be trained (see comment `# epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mysterious-platinum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T05:17:47.740244Z",
     "iopub.status.busy": "2021-05-08T05:17:47.740027Z",
     "iopub.status.idle": "2021-05-08T05:17:47.751063Z",
     "shell.execute_reply": "2021-05-08T05:17:47.750542Z",
     "shell.execute_reply.started": "2021-05-08T05:17:47.740215Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "srcs = [\n",
    "    { 'stream': lambda:open('boolq/train.jsonl', 'r'),\n",
    "      'keys': ['question', 'passage', 'answer'] },\n",
    "    { 'stream': lambda:open('boolq/dev.jsonl', 'r'),\n",
    "      'keys': ['question', 'passage', 'answer'] },\n",
    "    { 'stream': lambda:open('boolq-nat-perturb/train.jsonl', 'r'),\n",
    "      'keys': ['question', 'passage', 'roberta_hard'] }\n",
    "]\n",
    "model.train()\n",
    "for _ in range(0): # epochs\n",
    "    for src in srcs:\n",
    "        with src['stream']() as s:\n",
    "            for d in s:\n",
    "                q, p, a = itemgetter(src['keys'][0], src['keys'][1], src['keys'][2])(json.loads(d))\n",
    "                tokens = tokenizer('question:'+q+'\\ncontext:'+p, return_tensors='pt')\n",
    "                if len(tokens.input_ids[0]) > model.config.n_positions:\n",
    "                    continue\n",
    "                model(input_ids=tokens.input_ids,\n",
    "                    labels=tokenizer(str(a), return_tensors='pt').input_ids,\n",
    "                    attention_mask=tokens.attention_mask,\n",
    "                    use_cache=True\n",
    "                    ).loss.backward()\n",
    "model.eval(); # ; suppresses long output on jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-kitty",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Define query function\n",
    "As the model is ready, define the querying function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pediatric-grove",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T05:17:47.752470Z",
     "iopub.status.busy": "2021-05-08T05:17:47.752250Z",
     "iopub.status.idle": "2021-05-08T05:17:47.845461Z",
     "shell.execute_reply": "2021-05-08T05:17:47.844870Z",
     "shell.execute_reply.started": "2021-05-08T05:17:47.752441Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query(q='question', c='context'):\n",
    "    return strtobool(\n",
    "        tokenizer.decode(\n",
    "            token_ids=model.generate(\n",
    "                input_ids=tokenizer.encode('question:'+q+'\\ncontext:'+c, return_tensors='pt')\n",
    "            )[0],\n",
    "        skip_special_tokens=True,\n",
    "        max_length=3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-rainbow",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Querying on the task\n",
    "Now the actual task begins: Query the model with your ideas (see list `ideas`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "toxic-lemon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T05:39:54.534227Z",
     "iopub.status.busy": "2021-05-08T05:39:54.533994Z",
     "iopub.status.idle": "2021-05-08T05:39:59.255031Z",
     "shell.execute_reply": "2021-05-08T05:39:59.254404Z",
     "shell.execute_reply.started": "2021-05-08T05:39:54.534199Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Idea: The idea is to pollute the air instead of riding the bike.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to go cycling instead of driving the car.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to put your trash everywhere.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to reduce transport distances.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to put plants on all the roofs.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to forbid opensource vaccines.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to go buy an Iphone every five years.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to walk once every week in the nature.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to go buy Green bonds.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to go buy fast fashion.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to buy single-use items.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to drink plastic bottled water.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to use import goods.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to use buy more food than you need.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to eat a lot of meat.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to eat less meat.\n",
      "\tâœ… Good idea\n",
      "ğŸŒ Idea: The idea is to alwaays travel by plane.\n",
      "\tâŒ Bad idea\n",
      "ğŸŒ Idea: The idea is to opensource vaccines.\n",
      "\tâœ… Good idea\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ideas = [ 'The idea is to pollute the air instead of riding the bike.', # should be false\n",
    "              'The idea is to go cycling instead of driving the car.', # should be true\n",
    "              'The idea is to put your trash everywhere.', # should be false\n",
    "              'The idea is to reduce transport distances.', # should be true\n",
    "              'The idea is to put plants on all the roofs.', # should be true\n",
    "              'The idea is to forbid opensource vaccines.', # should be true\n",
    "              'The idea is to go buy an Iphone every five years.', # should be false \n",
    "              'The idea is to walk once every week in the nature.', # should be true  \n",
    "              'The idea is to go buy Green bonds.', # should be true  \n",
    "              'The idea is to go buy fast fashion.', # should be false\n",
    "              'The idea is to buy single-use items.', # should be false\n",
    "              'The idea is to drink plastic bottled water.', # should be false\n",
    "              'The idea is to use import goods.', # should be false\n",
    "              'The idea is to use buy more food than you need.', # should be false\n",
    "              'The idea is to eat a lot of meat.', # should be false\n",
    "              'The idea is to eat less meat.', # should be false\n",
    "              'The idea is to always travel by plane.', # should be false\n",
    "              'The idea is to opensource vaccines.' # should be false\n",
    "             \n",
    "            ]\n",
    "    for idea in ideas:\n",
    "        print('ğŸŒ Idea:', idea)\n",
    "        print('\\tâœ… Good idea' if query('Is the idea environmentally friendly?', idea) else '\\tâŒ Bad idea' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-incentive",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}