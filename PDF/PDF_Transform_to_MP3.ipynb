{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF - Transform to mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gTTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to convert pdf  file to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "def convert_pdf_to_string(file_path):\n",
    "\n",
    "\toutput_string = StringIO()\n",
    "\twith open(file_path, 'rb') as in_file:\n",
    "\t    parser = PDFParser(in_file)\n",
    "\t    doc = PDFDocument(parser)\n",
    "\t    rsrcmgr = PDFResourceManager()\n",
    "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\t    for page in PDFPage.create_pages(doc):\n",
    "\t        interpreter.process_page(page)\n",
    "\n",
    "\treturn(output_string.getvalue())\n",
    "\n",
    "                \n",
    "def convert_title_to_filename(title):\n",
    "    filename = title.lower()\n",
    "    filename = filename.replace(' ', '_')\n",
    "    return filename\n",
    "\n",
    "\n",
    "def split_to_title_and_pagenum(table_of_contents_entry):\n",
    "    title_and_pagenum = table_of_contents_entry.strip()\n",
    "    \n",
    "    title = None\n",
    "    pagenum = None\n",
    "    \n",
    "    if len(title_and_pagenum) > 0:\n",
    "        if title_and_pagenum[-1].isdigit():\n",
    "            i = -2\n",
    "            while title_and_pagenum[i].isdigit():\n",
    "                i -= 1\n",
    "\n",
    "            title = title_and_pagenum[:i].strip()\n",
    "            pagenum = int(title_and_pagenum[i:].strip())\n",
    "        \n",
    "    return title, pagenum\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Networks are Easily Fooled:\n",
      "High Confidence Prediction for Unrecognizable Images\n",
      "\n",
      "Installation Guide\n",
      "Updated 2015-01-13\n",
      "\n",
      "INSTALLATION GUIDE\n",
      "\n",
      "A. Overview\n",
      "This guide shows how to run the code used to produce the images in our paper: \n",
      "http://www.evolvingai.org/fooling\n",
      "\n",
      "B. Requirements\n",
      "Software:\n",
      "This is an installation process that requires two main software packages (included in this package):\n",
      "\n",
      "• Caffe: http://caffe.berkeleyvision.org\n",
      "\n",
      "◦ Our libraries installed to work with Caffe\n",
      "\n",
      "•\n",
      "\n",
      "Sferes: https://github.com/jbmouret/sferes2\n",
      "◦ Our libraries installed to work with Caffe\n",
      "\n",
      "▪ Cuda 6.0\n",
      "▪ Boost 1.52\n",
      "\n",
      "▪ OpenCV 2.4.10\n",
      "▪ Boost 1.52\n",
      "\n",
      "Computing Environment:\n",
      "\n",
      "• An MNIST experiment (Fig. 4, 5 in the paper) can be run directly on a local machine (4-core) \n",
      "\n",
      "within a reasonable amount of time (around 5 minutes or less for 200 generations) \n",
      "\n",
      "• An ImageNet experiment needs to be run on a cluster environment. It took us 4 days x 128 \n",
      "\n",
      "cores to run 5000 generations and produce 1000 images (Fig. 8 in the paper).\n",
      "\n",
      "C. Installation\n",
      "\n",
      "1.\n",
      "\n",
      "Install Caffe and its required libraries.\n",
      "\n",
      "◦ The specific version provided is different from the Caffe master branch and it has the \n",
      "modification that enables feeding OpenCV data from memory to a Caffe model for \n",
      "evaluation via ImageDataLayer.\n",
      "\n",
      "◦ Caffe installation guide: http://caffe.berkeleyvision.org/installation.html\n",
      "\n",
      "2. Find a model you want to “fool” or train one yourself. We used the BVLC CaffeNet model \n",
      "\n",
      "provided by Caffe.\n",
      "\n",
      "◦ See the list of models here.\n",
      "◦ Make sure that it is running and gives you validation / test errors as expected.\n",
      "\n",
      "3.\n",
      "\n",
      "Install Sferes and its required libraries:\n",
      "\n",
      "◦ The specific Sferes version provided has all the modules needed to run the experiment \n",
      "\n",
      "and is very similar to (but not the same as) the Sferes master branch.\n",
      "\n",
      "◦ Sferes installation guide: https://github.com/jbmouret/sferes2/wiki/Compilation\n",
      "\n",
      "4. Linking Caffe and Sferes:\n",
      "\n",
      "◦ Our code already does the linking between Caffe and Sferes:\n",
      "\n",
      "1\n",
      "\n",
      "\f",
      "Deep Neural Networks are Easily Fooled:\n",
      "High Confidence Prediction for Unrecognizable Images\n",
      "\n",
      "Installation Guide\n",
      "Updated 2015-01-13\n",
      "\n",
      "▪ Sending an image in memory (OpenCV::Mat) to Caffe for evaluation\n",
      "▪ Get the output confidence scores from the Caffe model for that image\n",
      "▪ See ./sferes/exp/images/fit/fit_map_deep_learning.hpp\n",
      "\n",
      "◦ Install the Caffe libraries\n",
      "\n",
      "▪ Install the Caffe library (caffe.so and caffe.a) and its headers so that Sferes can find \n",
      "\n",
      "it for compilation.\n",
      "• You can refer to ./sferes/install_caffe.sh to see how we install it on our system.\n",
      "\n",
      "▪ Modify Sferes waf configuration file according to your system\n",
      "\n",
      "In file: ./sferes/exp/images/wscript\n",
      "\n",
      "•\n",
      "• Make sure that the path in obj.includes = points to the correct locations \n",
      "\n",
      "5. Compile a Sferes experiment:\n",
      "\n",
      "◦ Our Sferes experiments for the paper are located in the ./sferes/exp/images folder\n",
      "◦ Update the experiment config to compile an experiment:\n",
      "\n",
      "▪ In file: ./sferes/exp/images/wscript\n",
      "▪ Modify the field obj.source = to a file name in the experiment folder\n",
      "\n",
      "◦ Make sure that the code compiles correctly with waf:\n",
      "\n",
      "▪ waf -- configure …  \n",
      "\n",
      "•\n",
      "\n",
      "see ./sferes/build.sh for example parameters we used on our system\n",
      "\n",
      "▪ waf build\n",
      "▪ waf -- exp images\n",
      "▪ This is the result of our working waf -- configure for your reference\n",
      "\n",
      "WARNING simplejson not found some function may not work \n",
      "module : [modules/nn2] \n",
      "module : [modules/map_elite] \n",
      "Check for program g++ or c++             : /usr/bin/g++ \n",
      "Check for program cpp                    : /usr/bin/cpp \n",
      "Check for program ar                     : /usr/bin/ar \n",
      "Check for program ranlib                 : /usr/bin/ranlib \n",
      "Checking for g++                         : ok  \n",
      "boost headers                            : Version 1_52 (/home/anh/src/sferes/include) \n",
      "library boost_serialization              : ok \n",
      "library boost_filesystem                 : ok \n",
      "library boost_system                     : ok \n",
      "library boost_unit_test_framework        : ok \n",
      "library boost_program_options            : ok \n",
      "library boost_graph                      : ok \n",
      "library boost_mpi                        : ok \n",
      "library boost_python                     : ok \n",
      "library boost_thread                     : ok \n",
      "Checking for header tbb/parallel_for.h   : not found \n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "Deep Neural Networks are Easily Fooled:\n",
      "High Confidence Prediction for Unrecognizable Images\n",
      "\n",
      "Installation Guide\n",
      "Updated 2015-01-13\n",
      "\n",
      "Checking for header tbb/parallel_for.h   : not found \n",
      "Checking for header mpi.h                : ok /usr/include/mpi \n",
      "Checking for SDL (optional)              : not found \n",
      "Checking for header Eigen/Core           : ok /home/anh/src/sferes/include \n",
      "Check for program ode-config             : not found \n",
      "Checking for ODE (optional)              : not found \n",
      "Checking for GSL (optional)              : not found \n",
      "\n",
      "6. List of experiment to reproduce :\n",
      "\n",
      "◦ Direct Encoding (section 3.1 and 3.3 in the paper)\n",
      "\n",
      "▪ MNIST: dl_map_elites_images_mnist_direct_encoding.cpp\n",
      "▪ ImageNet: dl_map_elites_images_imagenet_direct_encoding.cpp\n",
      "\n",
      "◦ Indirect Encoding (section 3.2 and 3.4 in the paper)\n",
      "▪ MNIST: dl_map_elites_images_mnist.cpp\n",
      "▪ ImageNet: dl_map_elites_images.cpp\n",
      "\n",
      "7. Configure the experiment in the cpp file:\n",
      "\n",
      "◦ After selecting an experiment and compiling successfully, now configure it as you want.\n",
      "◦ File ./sferes/exp/images/dl_images.hpp contains generic parameters which are by default \n",
      "\n",
      "in inherited (and can be overwritten) by the experiments:\n",
      "▪ Params::image::size : size of the images to evolve (default to 256)\n",
      "▪ Params::image::crop_size :  crop size according to Caffe config (default to 227)\n",
      "▪ Params::image::use_crops : use crop or not. \n",
      "\n",
      "• True: Use 10 crops \n",
      "•\n",
      "\n",
      "False: Use 1 center crop\n",
      "\n",
      "▪ Params::image::color : True/False for MNIST grayscale or ImageNet color images.\n",
      "▪ Params::image::num_categories : default to 1000 corresponding to 1000 ImageNet \n",
      "\n",
      "categories. Change to 10 for MNIST.\n",
      "• Note: in the experiment cpp file also update Params::ea::res_y to be equal to the \n",
      "\n",
      "num_categories unless you know MAP-Elites really well to experiment \n",
      "differently.\n",
      "\n",
      "◦ In the experiment cpp file (e.g. dl_map_elites_images.cpp):\n",
      "▪ Params::pop::nb_gen : the number of generations to run.\n",
      "▪ Params::pop::size : the number of population\n",
      "▪ Params::image::model_definition : path to the prototxt file used by your model\n",
      "\n",
      "•\n",
      "\n",
      "See the example prototxt file\n",
      "\n",
      "▪ Params::image::pretrained_model : path to your model\n",
      "▪ Params::pop::dump_period : how frequently your images will be printed out\n",
      "▪ To run on cluster with MPI, uncomment this line\n",
      "\n",
      "•\n",
      "\n",
      "typedef eval::MpiParallel<Params> eval_t;\n",
      "\n",
      "▪ To run locally on a single core, uncomment this line, and comment out the above\n",
      "\n",
      "3\n",
      "\n",
      "\f",
      "Deep Neural Networks are Easily Fooled:\n",
      "High Confidence Prediction for Unrecognizable Images\n",
      "\n",
      "Installation Guide\n",
      "Updated 2015-01-13\n",
      "\n",
      "•\n",
      "\n",
      "typedef eval::Eval<Params> eval_t;\n",
      "\n",
      "8. Test running your experiment:\n",
      "\n",
      "◦ The binary will be located in the directories:\n",
      "\n",
      "▪ ./sferes/default/exp/images\n",
      "▪ ./sferes/debug/exp/images\n",
      "\n",
      "◦ If running locally, you can test running this binary directly and the result will be written \n",
      "\n",
      "in a newly created directory: “mmm” (i.e. ./sferes/mmm/)\n",
      "▪ The fitness or confidence score of the champions in each generation will be written \n",
      "in the archive_x.dat (e.g., for generation 235, see ./sferes/mmm/archive_235.dat).\n",
      "• The first column is the category index\n",
      "• The second column is the fitness\n",
      "\n",
      "▪ Images are stored in ./sferes/mmm/map_gen_x (e.g., for generation 236, see \n",
      "\n",
      "./sferes/mmm/map_gen_236).\n",
      "\n",
      "9. To run on a cluster\n",
      "\n",
      "◦ We use 128 cores usually to run ImageNet experiments.\n",
      "◦ If you need help configuring, consult the file : ./sferes/submit_jobs.py. This is how we \n",
      "\n",
      "schedule jobs on a cluster environment.\n",
      "\n",
      "10. Caffe version\n",
      "\n",
      "◦ Our particular Caffe version requires a dummy source parameter in the prototxt in order \n",
      "\n",
      "to initialize the input data blobs at the IMAGE_DATA layer properly. \n",
      "▪ Please refer to the ./model directory on how we configure the prototxt\n",
      "\n",
      "◦ The batch size in the prototxt file is default to 10 as we use 10 crops per evaluation.\n",
      "\n",
      "For specific Sferes or Caffe questions, please see their github pages or Google groups.\n",
      "For other questions regarding these experiments from our paper, please don't hesitate to ask. :)\n",
      "\n",
      "Cheers,\n",
      "\n",
      "4\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_name = 'Installation_Guide.pdf' # .pdf file you want to convert\n",
    "print(convert_pdf_to_string(pdf_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = convert_pdf_to_string(pdf_name)\n",
    "from gtts import gTTS\n",
    "string_of_text = ''\n",
    "for text in rr:\n",
    "    string_of_text += text\n",
    "\n",
    "final_file = gTTS(text=string_of_text, lang='en')  # store file in variable\n",
    "final_file.save(\"Generated Speech.mp3\")  # save file to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
