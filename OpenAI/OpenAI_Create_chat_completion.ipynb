{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed187eef-9e55-4ce4-89d9-324281009010",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"OpenAI.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/OpenAI.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cdf0c-d312-4cb3-b736-eae6e535a1be",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# OpenAI - Create chat completion\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=OpenAI+-+Create+chat+completion:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42111b5-d8e9-4dda-a6f8-4724210e2b5f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #openai #chat #completion #response #python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582ce0c-61df-4099-bbf3-848e4b496a92",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fb727-0bb8-4840-9d06-bd46a3baf286",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-05-31 (Created: 2023-05-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc5490-6c22-4f49-9deb-bb34e62e00d0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook creates a model response for the given chat conversation. It uses OpenAI's API to generate a response based on the conversation context. This is useful for organizations that need to generate automated responses to customer inquiries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5468cd2-0441-451f-9e52-b7fa74cc6886",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/create?lang=python)\n",
    "- [OpenAI Documentation](https://openai.com/docs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ff847-adc5-494e-bed9-7abeee01cef9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f696c5-9a88-45d8-bac6-c9dc47647e53",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deaaa21-41ad-4c42-af17-134ae01bd5a0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import openai\n",
    "except:\n",
    "    !pip install openai --user\n",
    "    import openai\n",
    "import naas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300be19-0a39-4b37-af8e-65002d903364",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Variables\n",
    "- `api_key`: OpenAI API key. [Get your API key here](https://openai.com/docs/api-overview/).\n",
    "- `model`: ID of the model to use. You can find a list of available models and their IDs on the [OpenAI API documentation](https://platform.openai.com/docs/models/overview).\n",
    "- `temperature` (Defaults to 1): This is a value that controls the level of randomness in the generated text. A temperature of 0 will result in the most deterministic output, while higher values will result in more diverse and unpredictable output.\n",
    "- `max_tokens` (Defaults to 16): This is the maximum number of tokens (words or phrases) that the API should return in its response. The larger the value of max_tokens, the more text the API can generate, but it will also take longer for the API to generate the response. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096).\n",
    "- `messages_role`: The role of the author of this message. One of system, user, or assistant.\n",
    "- `messages_system`: The contents of the message.\n",
    "- `messages`: A list of messages describing the conversation so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d38cc-9654-4bbc-8913-f7ad7ebcfea5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = naas.secret.get(name=\"OPENAI_API_KEY\") or \"ENTER_YOUR_OPENAI_API_KEY\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "temperature = 0.9\n",
    "max_tokens = 2084\n",
    "messages_role = \"system\"\n",
    "messages_system = f\"\"\"\n",
    "Act as a chef whose name is Florent. \n",
    "Suggest delicious recipes that includes foods which are nutritionally beneficial but \n",
    "also easy & not time consuming enough therefore suitable for busy people like us among other factors such as cost effectiveness \n",
    "so overall dish ends up being healthy yet economical at same time! \n",
    "In your first message, you will present yourself and what you can do.\n",
    "You will start asking the user about its diet, health habbit and location and what he/she expect from you (a meal plan for the week, a dinner for friends,..) with questions in bullet point.\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": messages_role, \"content\": messages_system}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c4bae-0bd4-4d18-afc3-e31dc39f5756",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecee291-0cff-4106-a34c-f8b332caa12c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Send requests to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642fa2a-77d3-488d-9624-09417b8368e6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect with API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Create chat completion\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41d335-a2a1-48d1-9e8e-3c5d521aa221",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea64aa-eb7c-474e-b6a5-d12454c1a440",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc562c-9751-4049-ae6e-003ffcc5d2b4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "ce29f2ffe243c1ea092cd43ea7e5e42e8d39d6180230ab0ab9db873d168cbb4b",
   "notebook_path": "OpenAI/OpenAI_Create_chat_completion.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}