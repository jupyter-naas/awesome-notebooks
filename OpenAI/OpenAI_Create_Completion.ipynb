{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-packing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T14:22:16.610471Z",
     "iopub.status.busy": "2021-02-23T14:22:16.610129Z",
     "iopub.status.idle": "2021-02-23T14:22:16.627784Z",
     "shell.execute_reply": "2021-02-23T14:22:16.626866Z",
     "shell.execute_reply.started": "2021-02-23T14:22:16.610384Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"OpenAI.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/OpenAI.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-wilson",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# OpenAI - Create Completion\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=OpenAI+-+Create+Completion:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-programmer",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #openai #gpt3 #textcompletion #ai #machinelearning #deeplearning #nlp #datascience #artificialintelligence #tech #innovation #creativity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9f56e-561c-4f52-aef8-b861c9462107",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be301572-da34-443b-a888-8c218ae9e316",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-05-31 (Created: 2023-02-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec3cc1-b056-42d1-82b2-c7433c68f8c1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook guides you through the process of using OpenAI's Generative Pretrained Transformer 3 (GPT-3) model to build a text completion application. This notebook will show you how to fine-tune GPT-3 to generate text based on a given prompt, and then integrate it into a web application for easy usage. The end result will be a working text completion tool that can be used to generate new ideas, suggestions, or even entire texts with just a few inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcfc042-8807-4016-964a-de5700b84a40",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "- OpenAI API Documentation: https://platform.openai.com/docs/api-reference\n",
    "- GPT-3: https://openai.com/gpt-3/\n",
    "- Text Completion with Deep Learning: https://towardsdatascience.com/text-completion-with-deep-learning-4cce287eb716\n",
    "- Generative Pretrained Transformer 3 (GPT-3) Explained: https://towardsdatascience.com/gpt-3-explained-8bb5f9c0efc7\n",
    "- A Beginner's Guide to Generative Pre-trained Transformer 3 (GPT-3): https://towardsdatascience.com/a-beginners-guide-to-gpt-3-7d2a3dd3f9e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-truth",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-mediterranean",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-surfing",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import openai\n",
    "except:\n",
    "    !pip install openai --user\n",
    "    import openai\n",
    "import naas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7a5bb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup OpenAI\n",
    "- `api_key`: OpenAI API key. [Get your API key here](https://openai.com/docs/api-overview/).\n",
    "- `model`: ID of the model to use. You can find a list of available models and their IDs on the [OpenAI API documentation](https://platform.openai.com/docs/models/overview).\n",
    "- `prompt`: This is the text prompt that you want to send to the OpenAI API.\n",
    "- `temperature` (Defaults to 1): This is a value that controls the level of randomness in the generated text. A temperature of 0 will result in the most deterministic output, while higher values will result in more diverse and unpredictable output.\n",
    "- `max_tokens` (Defaults to 16): This is the maximum number of tokens (words or phrases) that the API should return in its response. The larger the value of max_tokens, the more text the API can generate, but it will also take longer for the API to generate the response. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee0cea-c6dd-4503-a646-a3fa7179c694",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = naas.secret.get(name=\"OPENAI_API_KEY\") or \"ENTER_YOUR_OPENAI_API_KEY\"\n",
    "model = \"text-davinci-003\"\n",
    "prompt = \"What is OpenAI?\"\n",
    "temperature = 0.6\n",
    "max_tokens = 2084"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-showcase",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-astrology",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Send requests to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-louisville",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect with API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Create completion\n",
    "response = openai.Completion.create(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-pacific",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T23:32:10.789097Z",
     "iopub.status.busy": "2021-07-02T23:32:10.788829Z",
     "iopub.status.idle": "2021-07-02T23:32:10.796900Z",
     "shell.execute_reply": "2021-07-02T23:32:10.796358Z",
     "shell.execute_reply.started": "2021-07-02T23:32:10.789033Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f7c86-b7bb-4f5d-9a1b-e492dd9580fd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e3b7b-6440-4844-8054-265f1aec65eb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the generated text\n",
    "text = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated text: \", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "af9a04ddc27f4c638f42e4ea923fc3a24aad1d38516af8f9dc4ad3b262d29647",
   "notebook_path": "OpenAI/OpenAI_Create_Completion.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}