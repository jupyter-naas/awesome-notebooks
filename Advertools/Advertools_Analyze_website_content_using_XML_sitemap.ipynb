{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da81fdb-1607-4dcd-8945-78492d41c20c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96049d01-11e9-4538-9012-57992898281e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Advertools - Analyze website content using XML sitemap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0bd6e-4a5c-472f-a473-a315e3738936",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #advertools #xml #sitemap #website #analyze #seo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089c7e4-b7a9-48ab-8320-e17847ad3b30",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Elias Dabbas](https://www.linkedin.com/in/eliasdabbas/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93cd7a5-1d4f-4bc6-94a2-b74461c7f538",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook helps you get an overview of a website's content by analyzing and visualizing its XML sitemap. It's also an important SEO audit process that can uncover some potential issues that might affect the website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84a0cf-6ba8-456a-8b42-1bf63e3a17f2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "- [advertools Sitemaps](https://advertools.readthedocs.io/en/master/advertools.sitemaps.html)\n",
    "- [XML Sitemap](https://en.wikipedia.org/wiki/Sitemaps)\n",
    "- [Sitemaps Protocol](https://www.sitemaps.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ef3a2-b261-45a8-bd64-52cb78b5f502",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530c66d-1a5b-47d1-8d80-01f21a83ac3e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d108a-44de-44b4-941f-f12795838c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T06:09:51.591920Z",
     "iopub.status.busy": "2023-05-16T06:09:51.591657Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting advertools\n",
      "  Downloading advertools-0.13.2-py2.py3-none-any.whl (310 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.1/310.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.4 in /opt/conda/lib/python3.9/site-packages (from advertools) (0.4.8)\n",
      "Collecting scrapy>=2.5.0\n",
      "  Downloading Scrapy-2.9.0-py2.py3-none-any.whl (277 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.2/277.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting twython>=3.8.0\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/ftp/.local/lib/python3.9/site-packages (from advertools) (7.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /home/ftp/.local/lib/python3.9/site-packages (from advertools) (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.0->advertools) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.0->advertools) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.0->advertools) (2.8.2)\n",
      "Collecting service-identity>=18.1.0\n",
      "  Using cached service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protego>=0.1.15\n",
      "  Using cached Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: lxml>=4.3.0 in /opt/conda/lib/python3.9/site-packages (from scrapy>=2.5.0->advertools) (4.9.2)\n",
      "Collecting Twisted>=18.9.0\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting parsel>=1.5.0\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting tldextract\n",
      "  Downloading tldextract-3.4.1-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=3.4.6 in /home/ftp/.local/lib/python3.9/site-packages (from scrapy>=2.5.0->advertools) (40.0.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /home/ftp/.local/lib/python3.9/site-packages (from scrapy>=2.5.0->advertools) (23.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from scrapy>=2.5.0->advertools) (49.6.0.post20210108)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Collecting PyDispatcher>=2.0.5\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from scrapy>=2.5.0->advertools) (21.0)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting zope.interface>=5.1.0\n",
      "  Downloading zope.interface-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting queuelib>=1.4.2\n",
      "  Using cached queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from twython>=3.8.0->advertools) (1.3.1)\n",
      "Requirement already satisfied: requests>=2.1.0 in /home/ftp/.local/lib/python3.9/site-packages (from twython>=3.8.0->advertools) (2.25.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.4.6->scrapy>=2.5.0->advertools) (1.14.6)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /home/ftp/.local/lib/python3.9/site-packages (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from protego>=0.1.15->scrapy>=2.5.0->advertools) (1.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ftp/.local/lib/python3.9/site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n",
      "Requirement already satisfied: pyasn1-modules in /opt/conda/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.2.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (21.2.0)\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Using cached constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ftp/.local/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (4.5.0)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->scrapy>=2.5.0->advertools) (2.4.7)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from tldextract->scrapy>=2.5.0->advertools) (3.9.0)\n",
      "Collecting requests-file>=1.4\n",
      "  Using cached requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy>=2.5.0->advertools) (2.20)\n",
      "Installing collected packages: PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, protego, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, twython, tldextract, service-identity, itemloaders, scrapy, advertools\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import advertools as adv\n",
    "except:\n",
    "    !pip install advertools --user\n",
    "    import advertools as adv\n",
    "import adviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a9e6f-71c4-4cb2-b9bc-32c23b18c4ba",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Variables\n",
    "- `sitemap_url`: URL of the sitemap to analyze, which can be\n",
    "    * The URL of an XML sitemap\n",
    "    * The URL of an XML sitemapindex\n",
    "    * The URL of a robots.txt file\n",
    "    * Normal and zipped formats are supported\n",
    "- `recursive`: If this is a sitemapindex, should all the sub-sitemaps also be  downloaded, parsed and combined into one DataFrame?\n",
    "- `max_workers`: Number of concurrent workers to fetch the sitemaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebcf1a5-23ce-49ca-aee9-aac7ff28a2e4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "sitemap_url = \"https://www.example.com/robots.txt\"\n",
    "recursive = True\n",
    "max_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6e918-ae61-4a78-9b71-a6ad5f530f53",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe9992-9fcb-4849-a69e-ced13c995aff",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Analyze website content using XML sitemap\n",
    "\n",
    "Getting the sitemap(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4949b9c4-f852-47f5-9889-3ccce1a0100a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "sitemap = adv.sitemap_to_df(\n",
    "    sitemap_url=sitemap_url,\n",
    "    max_workers=max_workers,\n",
    "    recursive=recursive)\n",
    "sitemap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907e816",
   "metadata": {},
   "source": [
    "Split URLs into their components for further analysis/understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e43820cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "urldf = adv.url_to_df(sitemap['loc'])\n",
    "urldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5491f8-3773-40e3-9e71-3058d4b7b870",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd817594-1b7f-4d02-a245-9e1dcd6ad2b6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Display results\n",
    "\n",
    "#### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc89d554-375c-4a10-a028-371d5b30781b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'errors' in sitemap:\n",
    "    from IPython.display import display\n",
    "    display(sitemap[sitemap['errors'].notnull()])\n",
    "else:\n",
    "    print('No errors found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34af8e",
   "metadata": {},
   "source": [
    "#### Duplicated URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ecab9fe-071a-47d8-a172-ae20ad3f4224",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicated = sitemap[sitemap['loc'].duplicated()]\n",
    "if not duplicated.empty:\n",
    "    display(duplicated)\n",
    "else:\n",
    "    print('No duplicated URLs found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec0200",
   "metadata": {},
   "source": [
    "#### URL counts per sitemap and sitemap sizes\n",
    "\n",
    "Each sitemap should have a maximumof 50,000 URLs, and its size should not exceek 50MB\n",
    "\n",
    "URL counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff6e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adviz.value_counts_plus(sitemap['sitemap'], name='Sitemap URLs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80fbcc",
   "metadata": {},
   "source": [
    "URL Sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0716b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitemap['sitemap_size_mb'].describe().to_frame().T.style.format('{:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b356e7",
   "metadata": {},
   "source": [
    "#### Count unique values of URL components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469a91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['scheme', 'netloc', 'dir_1', 'dir_2']:\n",
    "    display(adviz.value_counts_plus(urldf[col], name=col))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1255a",
   "metadata": {},
   "source": [
    "#### Visualize the structure of the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c44e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlsplit\n",
    "domain=urlsplit(sitemap_url).netloc\n",
    "\n",
    "adviz.url_structure(\n",
    "    urldf['url'].fillna(''),\n",
    "    items_per_level=30,\n",
    "    domain=domain,\n",
    "    height=750,\n",
    "    title=f'URL Structure: {domain} XML sitemap')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
