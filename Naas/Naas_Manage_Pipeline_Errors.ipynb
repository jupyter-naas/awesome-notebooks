{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deluxe-force",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Naas.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Naas.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-internship",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Naas - Manage Pipeline Errors\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=Naas+-+Manage+Pipeline+Errors:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097faf3-b2b9-41fd-8589-f7718b5f919a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #naas #pipeline #jupyter #notebook #dataanalysis #workflow #streamline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-guatemala",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Maxime Jublou](https://www.linkedin.com/in/maximejublou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be34c95-0dbe-4bf7-a5b5-067b12a54326",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-04-12 (Created: 2023-01-25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e0f26-7fdf-4351-9209-8bb54c5ef7e9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook is a guide that teaches you how to manage errors on your notebook pipeline using naas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "input_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funny-neighbor",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from naas.pipeline.pipeline import (\n",
    "    Pipeline,\n",
    "    DummyStep,\n",
    "    DummyErrorStep,\n",
    "    NotebookStep,\n",
    "    End,\n",
    "    ParallelStep,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d093c-0189-42c3-959f-64eed5530fd4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup NotebookStep\n",
    "For demonstration purposes, we used the `DummyStep` to illustrate its functionality.\n",
    "\n",
    "In order to create a pipeline, you should used the `NotebookStep()` which has three parameters:\n",
    "- the name (string) of the step\n",
    "- the notebook path (string) for execution\n",
    "- the parameters (dictionary) that are injected through papermill in the first cell or after the cell labeled \"parameters.\"\n",
    "\n",
    "`NotebookStep(\"My Notebook\", \"my_notebook.ipynb\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa346868-d375-4547-b11b-79311e3f1fc3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = DummyStep(\n",
    "    \"Collection\"\n",
    ")  # In this step, data can be collected from various sources such as databases, APIs, or file systems.\n",
    "cleaning = DummyStep(\n",
    "    \"Cleaning\"\n",
    ")  # Once the data is collected, it is often necessary to clean and preprocess it to remove any irrelevant or duplicate information. This step may involve tasks such as removing null values, correcting data formats, and standardizing column names.\n",
    "transformation1 = DummyStep(\n",
    "    \"Transformation 1\"\n",
    ")  # In this step, the data is transformed into the desired format, such as a flat file or a specific data model. This may involve tasks such as aggregating data, joining multiple tables, or calculating new fields.\n",
    "transformation2 = DummyStep(\n",
    "    \"Transformation 2\"\n",
    ")  # In this step, the data is transformed into the desired format, such as a flat file or a specific data model. This may involve tasks such as aggregating data, joining multiple tables, or calculating new fields.\n",
    "distribution = DummyErrorStep(\n",
    "    \"Distribution\"\n",
    ")  # In this step, the data is loaded into its final destination, such as a data warehouse, a data lake, or a specific application.\n",
    "notifications = DummyStep(\"Notifications\")  # Manage error on previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "display_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create Basic Pipeline & Manage error\n",
    "- Link your notebook using this syntax: `>>`\n",
    "- Create ParallelStep using this syntax: `[step1, step2]`\n",
    "- Manage error using this syntax: `step.on_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e4a38-75b1-475b-bc28-45db7effe45f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "\n",
    "(\n",
    "    pipeline\n",
    "    >> collection\n",
    "    >> cleaning\n",
    "    >> [transformation1, transformation2]\n",
    "    >> distribution\n",
    "    >> End()\n",
    ")\n",
    "\n",
    "distribution.on_error >> notifications\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edae619-f16d-4b31-a2c9-96e4aa0fa3a0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Monitor your pipeline in \"pipeline_executions\"\n",
    "When the pipeline is run, a \"pipeline_executions\" folder will be created in your file system. Inside this folder, you will be able to access each pipeline executions. If you use NotebookStep, executed notebooks will be stored in this folder. This allows you to easily review and analyze the results of the pipeline, and to troubleshoot any issues that may have occurred. The \"pipeline_executions\" folder is a valuable tool for understanding the performance of your pipeline and for making improvements to it over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "1f256fb50ad384b7ca469fca4ec3af4d9e67a7d37dee4022ea3e74246dfc01aa",
   "notebook_path": "Naas/Naas_Manage_Pipeline_Errors.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}