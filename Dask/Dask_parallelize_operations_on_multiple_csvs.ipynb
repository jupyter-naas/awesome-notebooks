{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-packing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T14:22:16.610471Z",
     "iopub.status.busy": "2021-02-23T14:22:16.610129Z",
     "iopub.status.idle": "2021-02-23T14:22:16.627784Z",
     "shell.execute_reply": "2021-02-23T14:22:16.626866Z",
     "shell.execute_reply.started": "2021-02-23T14:22:16.610384Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Dask.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Dask.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-wilson",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Dask - Parallelize operations on multiple csvs\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=Dask+-+Parallelize+operations+on+multiple+csvs:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-programmer",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #csv #pandas #snippet #read #dataframe #parallel #parallelize #dask #operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9f56e-561c-4f52-aef8-b861c9462107",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Minura Punchihewa](https://www.linkedin.com/in/minurapunchihewa/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcd3fa-3ed0-498e-81de-628f48aad67c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-04-12 (Created: 2022-04-13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook demonstrates how to use Dask to efficiently process and analyze multiple CSV files in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-truth",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6fa40-3e0a-44a3-9445-08878dddc89b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0884f99d-8abe-46c7-a345-373bff24f01c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead3b8e-c1c5-494b-9eb1-f9f3e7856920",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import Graphviz (install if not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b4329e9-3f11-4bed-a10a-eac6a5e0e0f5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import graphviz\n",
    "except:\n",
    "    !pip install --user graphviz\n",
    "    import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-mediterranean",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import Dask (install if not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "potential-surfing",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import dask.dataframe as dd\n",
    "except:\n",
    "    !python -m pip install \"dask[complete]\"\n",
    "    import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-trustee",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "continuous-melbourne",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = \"nycflights\"\n",
    "\n",
    "%env FOLDER_PATH=$folder_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740e0de-e423-4a72-9932-88e60095ed36",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Download dataset if it does not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "608e4e1d-4897-46d9-83c0-6e3f8dd14672",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "[[ -f \"$FOLDER_PATH/nycflights.csv\" ]] || (mkdir -p $FOLDER_PATH && wget -O $FOLDER_PATH/nycflights.csv  https://github.com/vaibhavwalvekar/NYC-Flights-2013-Dataset-Analysis/raw/master/flights.csv )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-showcase",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-astrology",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Read the CSV files from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "crude-louisville",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# when the actual data types of given columns cannot be inferred from the first few examples\n",
    "# they need to be specified manually\n",
    "# this is where the dtype parameters comes in\n",
    "df = dd.read_csv(\n",
    "    os.path.join(folder_path, \"*.csv\"),\n",
    "    parse_dates={\"Date\": [0, 1, 2]},\n",
    "    dtype={\n",
    "        \"TailNum\": str,\n",
    "        \"CRSElapsedTime\": float,\n",
    "        \"Cancelled\": bool,\n",
    "        \"dep_delay\": float,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-pacific",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T23:32:10.789097Z",
     "iopub.status.busy": "2021-07-02T23:32:10.788829Z",
     "iopub.status.idle": "2021-07-02T23:32:10.796900Z",
     "shell.execute_reply": "2021-07-02T23:32:10.796358Z",
     "shell.execute_reply.started": "2021-07-02T23:32:10.789033Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f7c86-b7bb-4f5d-9a1b-e492dd9580fd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Calculate the max of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4e3b7b-6440-4844-8054-265f1aec65eb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no operation is actually performed until the .compute() function is called\n",
    "df[\"dep_delay\"].max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70e722",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Visualize the parallel execution of the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85c919e2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the underlying task graph can be viewed to understand how the parallel execution takes place\n",
    "df.dep_delay.max().visualize(rankdir=\"LR\", size=\"12, 12!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b4be9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ba35d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a811dff",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a031acc6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# the equivalent operation performed using Pandas\n",
    "all_files = glob.glob(os.path.join(folder_path,'*.csv'))\n",
    "dfs = []\n",
    "for file in all_files:\n",
    "    dfs.append(pd.read_csv(file, parse_dates={'Date': [0, 1, 2]}))\n",
    "df = pd.concat(dfs, axis=0)\n",
    "df.dep_delay.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e78f52",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af9638aa",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# the entire operation again performed using Dask\n",
    "df = dd.read_csv(os.path.join(folder_path,'*.csv'), \n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': str,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool,\n",
    "                       'dep_delay': float})\n",
    "df['dep_delay'].max().compute()\n",
    "\n",
    "# Dask clearly performs better in comparison to Pandas\n",
    "# the performance benefits are more apparent when working on larger datasets\n",
    "# especially when the size of the data exceeds available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627f0a6-78c1-4b74-9efa-0202f9abde10",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "61bc9b898dcd8659c49a5ac5fe46a212b5f7217286b9bccdbfec9183f9cd9732",
   "notebook_path": "Dask/Dask_parallelize_operations_on_multiple_csvs.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}